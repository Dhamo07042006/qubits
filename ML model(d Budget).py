# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15UpC8H3ytRmi92K2bggcft2n0JxmQ2ye
"""

# Step 1: Import Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
from google.colab import files

# Step 2: Upload Dataset
uploaded = files.upload()  # Prompt to upload a CSV file

# Load the dataset
data_path = list(uploaded.keys())[0]
data = pd.read_csv(data_path)

# Step 3: Display Dataset and Column Names
print("First few rows of the dataset:")
print(data.head())  # Display the first few rows of the dataset

print("\nColumn names in the dataset:")
print(data.columns.tolist())  # Display column names as a list

print("\nData types of the columns:")
print(data.dtypes)  # Display data types

# Step 4: Define Analysis Function
def analyze_budget(data):
    # Check for missing values and drop rows with NaNs
    print("\nChecking for missing values...")
    print(data.isnull().sum())
    data.dropna(inplace=True)

    # Check if the dataset is empty after dropping NaNs
    if data.empty:
        raise ValueError("The dataset is empty after removing missing values. Please check your data.")

    # Identify numeric and categorical features
    numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_features = data.select_dtypes(include=['object']).columns.tolist()

    # Automatically choose target variable: the last numeric column
    if not numeric_features:
        raise ValueError("No numeric features found in the dataset.")

    target_variable = numeric_features[-1]
    print(f"\nUsing '{target_variable}' as the target variable.")

    # Remove target variable from features
    numeric_features.remove(target_variable)

    # One-hot encode categorical variables
    if categorical_features:
        data = pd.get_dummies(data, columns=categorical_features, drop_first=True)

    # Define features and target variable
    X = data.drop(target_variable, axis=1)
    y = data[target_variable]

    # Check for sufficient samples
    if len(y) < 2:
        raise ValueError("Not enough samples to perform train-test split.")

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train model
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # Evaluate model
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f'\nMean Absolute Error: {mae}')
    print(f'Mean Squared Error: {mse}')
    print(f'RÂ² Score: {r2}')

    # Feature importance
    importances = model.feature_importances_
    feature_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)

    # Visualize feature importance
    plt.barh(feature_importance.index, feature_importance.values)
    plt.xlabel('Feature Importance')
    plt.title('Feature Importance for Target Prediction')
    plt.show()

    # Compare predicted vs actual
    plt.figure(figsize=(12, 6))
    plt.plot(y_test.values, label='Actual Budget', marker='o', color='blue', alpha=0.7)
    plt.plot(y_pred, label='Predicted Budget', marker='x', color='orange', alpha=0.7)
    plt.title('Actual vs Predicted Budget')
    plt.xlabel('Sample Index')
    plt.ylabel('Budget Amount')
    plt.legend()
    plt.grid()
    plt.show()

# Step 5: Run the Analysis
analyze_budget(data)